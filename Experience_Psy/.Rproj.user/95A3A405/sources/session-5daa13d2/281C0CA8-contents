# Hypothèse 1 : Analyse de performance (Version Gemini)
# Ce script analyse les données d'une expérience de neuropsychologie
# pour tester si la nature animée des distracteurs affecte la performance.
# Il intègre des pratiques de code robustes (gestion de projet, modélisation mixte).

# ===================================================================
# 0. SETUP : CHARGEMENT DES LIBRAIRIES ET CONFIGURATION
# ===================================================================

# Bloc pour installer et charger les packages nécessaires
# 0. Met à jour xfun avant tout (dans une session fraîche)
if (!requireNamespace("xfun", quietly = TRUE) ||
    packageVersion("xfun") < "0.52.0") {
  install.packages("xfun")
}

# 1. Liste des packages
packages <- c(
  "tidyverse", "here", "readxl", "lme4", "performance",
  "sjPlot", "emmeans", "effectsize", "gtsummary"
)

# 2. Installe et charge
for (p in packages) {
  if (!require(p, character.only = TRUE)) {
    install.packages(p)
    library(p, character.only = TRUE)
  }
}

# Définir le thème ggplot pour la cohérence des graphiques
theme_set(theme_minimal() + theme(
  plot.title = element_text(hjust = 0.5),
  plot.subtitle = element_text(hjust = 0.5)
))


# ===================================================================
# 1. CHARGEMENT ET PRÉ-TRAITEMENT DES DONNÉES BRUTES
# ===================================================================

# Chemin vers le dossier des données brutes en utilisant `here` pour la portabilité
# Adaptez "data/raw_data" si votre structure de dossier est différente
csv_dir <- here::here("data", "raw_data")

# Lister les fichiers CSV, en excluant ceux qui sont vides
files <- list.files(
  path       = csv_dir,
  pattern    = "_Emotion.*\\.csv$",
  full.names = TRUE
)
files <- files[file.info(files)$size > 0]

# Fonction pour traiter chaque fichier individuel
process_data <- function(fp) {
  pid <- str_extract(basename(fp), "\\d+(?=_Emotion)")
  df  <- read.csv(fp, header = TRUE, stringsAsFactors = FALSE)

  # Ignorer les fichiers avec un nombre d'essais insuffisant
  if (nrow(df) < 44) {
    stop("Moins de 44 lignes, nombre d'essais insuffisant.")
  }

  df <- df[44:nrow(df), ]

  df %>%
    mutate(
      participant   = pid,
      Valence   = factor(ifelse(str_detect(ImageFile, regex("NEGA", ignore_case = TRUE)),
                                "Negative", "Neutral")),
      condition     = case_when(
        grepl("FIX", ImagesDistracteursFile, ignore.case = TRUE)     ~ "Fixes",
        grepl("anim", ImagesDistracteursFile, ignore.case = TRUE) ~ "Animées",
        TRUE                                                         ~ NA_character_
      ),
      is_distractor = grepl("Distracteurs", ImagesDistracteursFile, ignore.case = TRUE),
      correct       = case_when(
        is_distractor & mouse.clicked_name == "Faux" ~ 1,
        !is_distractor & mouse.clicked_name == "Vrai" ~ 1,
        TRUE                                         ~ 0
      )
    ) %>%
    # Garder uniquement les essais correspondant à nos conditions
    filter(!is.na(condition))
}

# Appliquer la fonction à chaque fichier, en gérant les erreurs potentielles
df_list <- map(files, function(fp) {
  tryCatch(
    process_data(fp),
    error = function(e) {
      warning(sprintf("→ Fichier '%s' ignoré : %s", basename(fp), e$message))
      return(NULL)
    }
  )
})

# Combiner tous les dataframes en un seul
df_all <- bind_rows(df_list)


# ===================================================================
# 2. FUSION AVEC LES COVARIABLES
# ===================================================================

# Charger les données des participants (âge, sexe, etc.)
# Adaptez "data/covariates/TABLEAU-PARTICIPANTS 2.xlsx" si nécessaire
covariates_path <- here::here("data", "covariates", "TABLEAU-PARTICIPANTS 3.xlsx")
participants_df <- read_excel(covariates_path)

# Fusionner les données d'essais avec les covariables
df_full <- df_all %>%
  left_join(participants_df, by = "participant")

# Centrer les variables continues et factoriser les variables catégorielles
df_full <- df_full %>%
  mutate(
    age_c        = scale(Âge, center = TRUE, scale = FALSE)[,1],
    depression_c = scale(depression, center = TRUE, scale = FALSE)[,1],
    sex          = factor(Sexe),
    education    = factor(education, ordered = TRUE, levels = c("Secondaire", "Bâchelier", "Universitaire"))
  )

# ===================================================================
# 2.1 STATISTIQUES DESCRIPTIVES
# ===================================================================


# 2. Résumé Sexe
sex_summary <- participants_df %>%
  count(Sexe) %>%
  mutate(
    pct   = round(n / sum(n) * 100, 1),
    label = paste0(n, " (", pct, " %)")
  )

# 3. Résumé Âge
age_summary <- participants_df %>%
  summarise(
    median = median(Âge, na.rm = TRUE),
    q1     = quantile(Âge, 0.25, na.rm = TRUE),
    q3     = quantile(Âge, 0.75, na.rm = TRUE)
  ) %>%
  mutate(
    label = paste0(median, " (", q1, "–", q3, ")")
  )

# 4. Résumé Niveau d’études
edu_summary <- participants_df %>%
  count(education) %>%
  mutate(
    pct   = round(n / sum(n) * 100, 1),
    label = paste0(n, " (", pct, " %)")
  )

# 5. Construction du tableau final
table1 <- tibble::tibble(
  Variables = c(
    "Sexe, n (%)",
    paste0("  • ", sex_summary$Sexe),
    "Âge (années)",
    "Niveau d’études, n (%)",
    paste0("  • ", edu_summary$education)
  ),
  `Total (n = 41)` = c(
    "",
    sex_summary$label,
    age_summary$label,
    "",
    edu_summary$label
  )
)

# 6. Affichage du tableau (Markdown ou LaTeX)
knitr::kable(table1, format = "markdown", align = c("l", "c"), 
             caption = "Tableau 1 : Répartition des participants par sexe, âge et niveau d’études")


# ===================================================================
# 3. ANALYSE EXPLORATOIRE (EDA)
# ===================================================================

# Visualisation simple de la performance moyenne par condition
library(dplyr)
library(ggplot2)
library(scales)

df_full %>%
  group_by(condition) %>%
  summarise(mean_perf = mean(correct), .groups = "drop") %>%
  ggplot(aes(x = condition, y = mean_perf, fill = condition)) +
  geom_col(width = 0.4, show.legend = FALSE) +            # barres plus fines
  geom_text(aes(label = percent(mean_perf, accuracy = 1)),
            vjust = -0.5) +
  scale_y_continuous(
    labels = percent_format(accuracy = 1),
    limits = c(0, 1),
    expand = expansion(mult = c(0, 0.05))
  ) +
  labs(
    title    = "Performance de reconnaissance par condition",
    subtitle = "Taux de réponses correctes moyen",
    x        = "Conditions",
    y        = "Pourcentage de réponses correctes"
  ) +
  theme_minimal() +
  theme(
    plot.title     = element_text(hjust = 0.5, face = "bold"),  # titre centré
    plot.subtitle  = element_text(hjust = 0.5),
    axis.text.x    = element_text(size = 11),
    axis.text.y    = element_text(size = 11)
  )



# Graphique rigoureux pour mémoire de neuropsychologie
library(dplyr)
library(ggplot2)
library(scales)

# Calcul des statistiques descriptives
stats_summary <- df_full_sans22 %>%
  group_by(condition) %>%
  summarise(
    n = n(),
    mean_perf = mean(correct),
    sd_perf = sd(correct),
    se_perf = sd(correct) / sqrt(n()),
    # Intervalle de confiance à 95%
    ci_lower = mean_perf - qt(0.975, df = n()-1) * se_perf,
    ci_upper = mean_perf + qt(0.975, df = n()-1) * se_perf,
    .groups = "drop"
  )

# Graphique principal
ggplot(stats_summary, aes(x = condition, y = mean_perf)) +
  # Barres principales avec couleurs distinctes
  geom_col(width = 0.6, 
           aes(fill = condition),
           alpha = 0.8, 
           color = "black", 
           show.legend = FALSE) +
  
  # Couleurs personnalisées
  scale_fill_manual(values = c("Animées" = "#E74C3C", "Fixes" = "#3498DB")) +
  
  # Intervalles de confiance (barres d'erreur noires épaisses)
  geom_errorbar(
    aes(ymin = ci_lower, ymax = ci_upper),
    width = 0.25,
    size = 1,
    color = "black"
  ) +
  
  # Pourcentages au-dessus des barres d'erreur
  geom_text(
    aes(y = ci_upper, label = paste0(round(mean_perf * 100, 1), "%")),
    vjust = -0.5,
    size = 4,
    fontface = "bold"
  ) +
  
  # Annotations élégantes avec statistiques détaillées
  geom_text(
    aes(x = condition, 
        y = mean_perf * 0.15,  # Position dans le bas de chaque barre
        label = paste0("IC 95%: [", round(ci_lower, 3), "; ", round(ci_upper, 3), "]\n",
                       "SD = ", round(sd_perf, 3))), #" (n = ", n, ")")),
    size = 3,
    color = "white",
    fontface = "bold",
    lineheight = 0.9
  ) +
  
  # Échelle et limites
  scale_y_continuous(
    labels = percent_format(accuracy = 1),
    limits = c(0, max(stats_summary$ci_upper) * 1.12),
    breaks = seq(0, 1, by = 0.2),
    expand = c(0, 0)
  ) +
  
  # Labels
  labs(
    title = "Taux de reconnaissance par condition expérimentale",
    x = "Condition",
    y = "Taux de réponses correctes",
    caption = "Les barres d'erreur représentent les intervalles de confiance à 95%\nSD = Écart-type, IC = Intervalle de confiance"
  ) +
  
  # Thème épuré
  theme_classic() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.caption = element_text(hjust = 0.5, size = 10, color = "gray40"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 11),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black")
  )

# Tableau des statistiques descriptives à inclure dans le mémoire
print("Statistiques descriptives :")
stats_table <- stats_summary %>%
  mutate(
    M = round(mean_perf, 3),
    SD = round(sd_perf, 3),
    IC_95_inf = round(ci_lower, 3),
    IC_95_sup = round(ci_upper, 3)
  ) %>%
  select(condition, n, M, SD, IC_95_inf, IC_95_sup)

print(stats_table)

# ===================================================================
# 4. MODÉLISATION STATISTIQUE (GLMM)
# ===================================================================

# --- Étape 4.1 : Construction et comparaison des modèles ---

# Modèle 1 : Modèle logistique simple (sans effets aléatoires)
glm1 <- glm(correct ~ condition, data = df_full, family = binomial)

# Modèle 2 : Modèle mixte avec intercept aléatoire pour les participants
glmer1 <- glmer(
  correct ~ condition + (1 | participant),
  data = df_full, family = binomial, control = glmerControl(optimizer = "bobyqa")
)

# Modèle 3 : Ajout de l'item (image) comme effet aléatoire
glmer2 <- glmer(
  correct ~ condition + (1 | participant) + (1 | ImagesDistracteursFile),
  data = df_full, family = binomial, control = glmerControl(optimizer = "bobyqa")
)

# Comparaison pour justifier la structure des effets aléatoires
# Un p < 0.05 indique que le modèle plus complexe est significativement meilleur
print(anova(glm1, glmer1, glmer2))
# Conclusion de anova() : glmer2 est généralement le meilleur s'il converge et est justifié.
# Nous utiliserons glmer1 pour la suite par souci de simplicité si l'effet de l'item est faible.

# Modèle 4 : Modèle simple avec covariables (notre modèle principal)
glmer_simple <- glmer(
  correct ~ condition + age_c + sex + education + depression_c + (1 | participant),
  data = df_full, family = binomial, control = glmerControl(optimizer = "bobyqa")
)

# Modèle 5 : Modèle avec interaction Condition * Dépression
glmer_int <- glmer(
  correct ~ condition * depression_c + age_c + sex + education + (1 | participant),
  data = df_full, family = binomial, control = glmerControl(optimizer = "bobyqa")
)

# Test du rapport de vraisemblance pour l'interaction
print(anova(glmer_simple, glmer_int))
# Conclusion : si p > 0.05, l'interaction n'améliore pas le modèle.

# --- Étape 4.2 : Interprétation du modèle final (glmer_simple) ---

# Vérifier la performance (pseudo-R2) et les diagnostics du modèle
print(performance::r2(glmer_simple))
print(performance::check_model(glmer_simple))

# Afficher un tableau résumé élégant des résultats du modèle
# Exp(B) sont les Odds Ratios
tbl_regression(glmer_simple, exponentiate = TRUE) %>%
  as_gt() %>%
  gt::gtsave(here::here("output", "model_summary.html")) # Sauvegarde en HTML
print(tbl_regression(glmer_simple, exponentiate = TRUE))


# Visualiser les prédictions du modèle (effets fixes)
plot_model(glmer_simple, show.values = TRUE, value.offset = .3) +
  labs(title = "Effets des prédicteurs sur la probabilité de réponse correcte")

# Visualiser l'effet spécifique de l'éducation
plot_model(glmer_simple, type = "pred", terms = "education") +
  labs(title = "Performance prédite par niveau d'études")


# ===================================================================
# 5. ANALYSE CONFIRMATOIRE (ANOVA À MESURES RÉPÉTÉES)
# ===================================================================
# Utile pour comparer avec des approches plus "classiques".

# Agréger les données par participant et condition
summary_df <- df_full %>%
  group_by(participant,Valence,condition, age_c, sex, education, depression_c) %>%
  summarise(pct_correct = mean(correct), .groups = "drop")

# ANCOVA à mesures répétées
rm_ancova <- aov(
  pct_correct ~ condition * education + age_c + sex + depression_c +
                Error(participant / (condition * education)),
  data = summary_df
)
print(summary(rm_ancova))

# ANCOVA à mesures répétées
rm_ancova <- aov(
  pct_correct ~ condition +
    Error(participant / (condition)),
  data = summary_df
)
print(summary(rm_ancova))

install.packages("ez")
library(ez)

res_aov <- ezANOVA(
  data = df_full,
  dv = correct,
  wid = participant,
  within = .(condition, Valence),
  type = 3,
  detailed = TRUE,
  return_aov = TRUE
)
print(res_aov)

# Paired t-test directement en long
t_test_res <- t.test(pct_correct ~ condition, data = summary_df)
print(t_test_res)
# Calcul de la taille d'effet (Eta-squared partiel)
print(effectsize::eta_squared(rm_ancova, partial = TRUE))

# Tests post-hoc sur l'effet de l'éducation
emm_edu <- emmeans(rm_ancova, ~ education)
print(contrast(emm_edu, method = "pairwise", adjust = "tukey"))


# ===================================================================
# 6. CONCLUSION
# ===================================================================

# Basé sur le GLMM (glmer_simple), le principal prédicteur de la performance
# est le niveau d'études. Les participants de niveau universitaire montrent
# une performance significativement supérieure à ceux du secondaire (voir table et graphiques).
#
# La condition expérimentale (Fixed vs. Animated) n'a pas d'effet significatif
# sur la performance (p > 0.4), et ce, même après contrôle des covariables.
#
# Les autres variables (âge, sexe, dépression) n'ont pas non plus d'effet
# statistiquement significatif. L'hypothèse d'une interaction entre la condition
# et le score de dépression n'est pas soutenue par les données.
#
# En conclusion, l'hypothèse 1 est infirmée : la présentation animée
# n'améliore pas la reconnaissance dans cette tâche. Le niveau d'études
# est le seul facteur déterminant de la performance.


# ===================================================================
# 7. HYPOTHÈSE 2 (À DÉVELOPPER)
# ===================================================================

# Hypothèse concernant l'évaluation émotionnelle : Les participants évalueront les
# images animées comme étant plus émotionnellement intenses que les images non-animées,
# avec des différences notables en fonction de la valence émotionnelle (négative vs neutre).

# Le code pour tester cette hypothèse sera ajouté ici.
